{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMIsUCBftUJssKijvulToPC"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["!pip install TwitterApi"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-uefkyAmCQcX","executionInfo":{"status":"ok","timestamp":1684074200797,"user_tz":-330,"elapsed":4223,"user":{"displayName":"2022 18059","userId":"02450271169094688564"}},"outputId":"2e63a485-8004-448b-d465-60a37b1805f3"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting TwitterApi\n","  Downloading TwitterAPI-2.8.2.tar.gz (12 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from TwitterApi) (2.27.1)\n","Requirement already satisfied: requests_oauthlib in /usr/local/lib/python3.10/dist-packages (from TwitterApi) (1.3.1)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->TwitterApi) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->TwitterApi) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->TwitterApi) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->TwitterApi) (3.4)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests_oauthlib->TwitterApi) (3.2.2)\n","Building wheels for collected packages: TwitterApi\n","  Building wheel for TwitterApi (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for TwitterApi: filename=TwitterAPI-2.8.2-py3-none-any.whl size=14881 sha256=c555235d21b9cf90f9807838fa0b4c55301fc1401a12361a3bdb2527393594e3\n","  Stored in directory: /root/.cache/pip/wheels/aa/d3/ce/649017b934d001f7113c8f461dedf29da03e4cbe2894d5f145\n","Successfully built TwitterApi\n","Installing collected packages: TwitterApi\n","Successfully installed TwitterApi-2.8.2\n"]}]},{"cell_type":"code","source":["!pip install pyspark"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PMj376tImDY3","executionInfo":{"status":"ok","timestamp":1684074231748,"user_tz":-330,"elapsed":30981,"user":{"displayName":"2022 18059","userId":"02450271169094688564"}},"outputId":"5bbdfdf1-ee4c-4f76-acea-17e8f8bb99e4"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pyspark\n","  Downloading pyspark-3.4.0.tar.gz (310.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.8/310.8 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n","Building wheels for collected packages: pyspark\n","  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pyspark: filename=pyspark-3.4.0-py2.py3-none-any.whl size=311317130 sha256=5e793bc63159711d63f5dddde51e6c3b204d3c7c2fe25cb9519fe30a1b612544\n","  Stored in directory: /root/.cache/pip/wheels/7b/1b/4b/3363a1d04368e7ff0d408e57ff57966fcdf00583774e761327\n","Successfully built pyspark\n","Installing collected packages: pyspark\n","Successfully installed pyspark-3.4.0\n"]}]},{"cell_type":"code","source":["%load_ext sql"],"metadata":{"id":"P4PhbcW1DeSK","executionInfo":{"status":"ok","timestamp":1684074232968,"user_tz":-330,"elapsed":1226,"user":{"displayName":"2022 18059","userId":"02450271169094688564"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["from pyspark.sql.types import *\n","from pyspark.sql import SparkSession, DataFrame, Row\n","from pyspark.sql.functions import year, month, dayofweek, hour, weekofyear, date_format, \\\n","                                  udf, col, lit, struct, isnan, count, when\n"],"metadata":{"id":"ItDJx_ud6HiJ","executionInfo":{"status":"ok","timestamp":1684074232970,"user_tz":-330,"elapsed":17,"user":{"displayName":"2022 18059","userId":"02450271169094688564"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","import requests\n","import datetime\n","import time\n","import json\n","import csv"],"metadata":{"id":"JB1VKzv8By7v","executionInfo":{"status":"ok","timestamp":1684074232971,"user_tz":-330,"elapsed":16,"user":{"displayName":"2022 18059","userId":"02450271169094688564"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["from urllib.parse import urljoin\n","from functools import reduce"],"metadata":{"id":"FKcVUDnxDLEu","executionInfo":{"status":"ok","timestamp":1684074232972,"user_tz":-330,"elapsed":16,"user":{"displayName":"2022 18059","userId":"02450271169094688564"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["from TwitterAPI import TwitterAPI"],"metadata":{"id":"q4XnhrlICL64","executionInfo":{"status":"ok","timestamp":1684074232973,"user_tz":-330,"elapsed":15,"user":{"displayName":"2022 18059","userId":"02450271169094688564"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["spark = SparkSession \\\n","    .builder \\\n","    .config(\"spark.jars.packages\", \"org.apache.hadoop:hadoop-aws:2.7.0\") \\\n","    .appName(\"ETL_CryptocurrencyInsight\") \\\n","    .getOrCreate()"],"metadata":{"id":"3faPQJ9X6P3g","executionInfo":{"status":"ok","timestamp":1684074254930,"user_tz":-330,"elapsed":21971,"user":{"displayName":"2022 18059","userId":"02450271169094688564"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["def extract_tradingdata(symbol):\n","    \"\"\"\n","    Description: Collect URL and all parameters. The interval is set to 1d fetching the daily close.\n","                 No specific headers needed as it is a public API.\n","                 Note: To avoid IP ban the number of API calls muste be < 100 calls/minute.\n","    Parameters:\n","        symbol: Describes the traidingpair (cryptocurrency asset) for which trading data being requested.\n","    Returns:\n","        response: Contains the response from the API call to the cryptocurrency exchange.\n","    \"\"\"\n","    \n","    baseurl = \"https://api.binance.com\"\n","    path = \"/api/v3/klines\"\n","    headers = None\n","    params = {\n","        'symbol': symbol,\n","        'interval': '1d'\n","    }\n","    url = urljoin(baseurl, path)\n","    \n","    # Requesting data from cryptocurrency exchange for specific symbol\n","    response = requests.get(url, headers=headers, params=params)\n","    \n","    print(\"Success: Call to crypto currency exchange executed\")\n","    return response\n","    \n","def get_tradingdata(symbol):\n","    \"\"\"\n","    Description: The function is calling the API of an cryptocurrency exchange getting the trading details for\n","                 for a specific cryptocurrency asset. Afterwards it transforms the trading data.\n","    Parameters:\n","        symbol: Describes the traidingpair (cryptocurrency asset) for which trading data being requested.\n","    Returns:\n","        df_marketdata: Spark dataframe containing the trading data which are matched with the corresponding symbol.\n","    \"\"\"\n","    \n","    # Execute the trading data extraction from datasource\n","    response = extract_tradingdata(symbol)\n","\n","    # If the response is successful and data are being fetched prepare dataframe containing marketdata\n","    if response.status_code == 200:\n","\n","        # Extract trading details and make them available to the application\n","        # Define columns for dataframe based on API description from cryptocurrency exchange. \n","        # Source: https://github.com/binance-exchange/binance-official-api-docs/blob/master/rest-api.md#general-api-information\n","        content_tradingdata = response.json()   \n","        columns_tradingdata = ['open_time', \n","                              'open', \n","                              'high', \n","                              'low', \n","                              'close', \n","                              'volume', \n","                              'close_time', \n","                              'quote_asset_volume', \n","                              'number_of_trades', \n","                              'taker_buy_base_asset_volume', \n","                              'taker_buy_quote_asset_volume', \n","                              'unclassfied']\n","        df_tradingdata = spark.createDataFrame(content_tradingdata, columns_tradingdata)\n","\n","        # Overwritting trading dataframe by adjusting datatypes and adding symbol column\n","        # ensuring the trading details are assigned to the correct cryptocurrency\n","        df_tradingdata = df_tradingdata.selectExpr(\"cast(open_time as long) open_time\", \n","                                                  \"cast(open as decimal(20,10)) open\", \n","                                                  \"cast(high as decimal(20,10)) high\", \n","                                                  \"cast(low as decimal(20,10)) low\", \n","                                                  \"cast(close as decimal(20,10)) close\",\n","                                                  \"cast(volume as decimal(20,10)) volume\",\n","                                                  \"cast(close_time as long) close_time\",\n","                                                  \"cast(quote_asset_volume as decimal(20,10)) quote_asset_volume\",\n","                                                  \"cast(number_of_trades as integer) number_of_trades\",\n","                                                  \"cast(taker_buy_base_asset_volume as decimal(20,10)) taker_buy_base_asset_volume\",\n","                                                  \"cast(taker_buy_quote_asset_volume as decimal(20,10)) taker_buy_quote_asset_volume\") \\\n","                                                  .withColumn(\"symbol\", lit(symbol))\n","        \n","        print(\"Success: Trading data were extracted\")\n","        return df_tradingdata\n","\n","    else:\n","        print(\"Crypto Currency API not available. Please try later\")  \n","\n","def get_marketdata(trading_pair_symbols):       \n","    \"\"\"\n","    Description: Creates a dataframe containing trading data for all requested cryptocurrency assets (marketdata).\n","    Parameters: \n","        trading_pair_symbols: List containing cryptocurrency assets symbols.\n","    Returns: \n","        None\n","    \"\"\"\n","    \n","    # Merges dataframes containing trading details for each cryptocurrency into one dataframe containing all data (marketdata)\n","    series_tradingdata = []\n","    for trading_pair_symbol in trading_pair_symbols:\n","        series_tradingdata.append(get_tradingdata(trading_pair_symbol))\n","    \n","    # Execute DAG and combine collection of trading data dataframes \n","    return reduce(DataFrame.unionAll, series_tradingdata)\n","\n","def transform_marketdata(df_marketdata):       \n","    \"\"\"\n","    Description: Process marketdata and split it into three tables following star schema approach.\n","                 The fact table (df_marketdata_trade) created contains trading metrics. The time table \n","                 (df_marketdata_time) is descriptive and contains related trading times. The symbol \n","                 table (df_marketdata_symbol) contains symbols (trading pairs). The relation between the\n","                 dataframes is described by the closing time (id).             \n","    Parameters: \n","        df_marketdata: Contains all marketdata as result from data extraction\n","    Returns: \n","        None\n","    \"\"\"\n","    # @udf: Extract datetime based on the timestamp (in ms)\n","    get_datetime_udf = udf(lambda ts: datetime.datetime.fromtimestamp(ts / 1000.0).strftime(\"%Y-%m-%d %H:%M:%S\"))\n","    \n","    # Convert timestamp to datetime and rename closing time to id\n","    # Note: The closing time acts as id as it is unique and allows to combine different marketdata dataframes \n","    df_marketdata = df_marketdata.withColumn(\"datetime\", get_datetime_udf(df_marketdata.close_time)) \\\n","                                 .withColumnRenamed(\"close_time\",\"id\")\n","    \n","    # Ensure data quality dropping null values and duplicates in id. \n","    df_marketdata.na.drop(subset=[\"id\"]).dropDuplicates([\"id\"])\n","    \n","    # Create time table dataframe for marketdata. The id is expressed by the closing time. \n","    df_marketdata_time = df_marketdata.select([\"id\",\n","                                               month(\"datetime\").alias(\"month\"),\n","                                               year(\"datetime\").alias(\"year\"),\n","                                               dayofweek(\"datetime\").alias(\"weekday\"),\n","                                               weekofyear(\"datetime\").alias(\"weekofyear\"),\n","                                               \"datetime\"])\n","    \n","    # Create dataframe trade table containing all revelant details.\n","    df_marketdata_trade = df_marketdata.select(\"id\",\n","                                               \"open\",\n","                                               \"close\",\n","                                               \"high\",\n","                                               \"low\",\n","                                               \"quote_asset_volume\",\n","                                               \"number_of_trades\",\n","                                               \"taker_buy_base_asset_volume\",\n","                                               \"taker_buy_quote_asset_volume\")\n","    \n","    # Create dataframe trade table containing all revelant details.\n","    df_marketdata_symbol = df_marketdata.select(\"id\",\n","                                                \"symbol\")\n","    \n","    print(\"Success: Marketdata were transformed\")\n","    return df_marketdata_time, df_marketdata_trade, df_marketdata_symbol\n","\n","## Receive all marketdata for cryptocurrency assets\n","trading_pair_symbols = [\"BTCUSDT\", \"ETHUSDT\", \"XRPUSDT\"]\n","df_marketdata = get_marketdata(trading_pair_symbols)\n","\n","## Split the marketdata into different tables following star schema\n","df_marketdata_time, df_marketdata_trade, df_marketdata_symbol = transform_marketdata(df_marketdata)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":484},"id":"mX6PWqhXCqiP","executionInfo":{"status":"error","timestamp":1684013979770,"user_tz":-330,"elapsed":689,"user":{"displayName":"2022 18059","userId":"02450271169094688564"}},"outputId":"cdff9d31-3ec4-486b-a505-099c884bcede"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Success: Call to crypto currency exchange executed\n","Crypto Currency API not available. Please try later\n","Success: Call to crypto currency exchange executed\n","Crypto Currency API not available. Please try later\n","Success: Call to crypto currency exchange executed\n","Crypto Currency API not available. Please try later\n"]},{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-15-97712bed2c7d>\u001b[0m in \u001b[0;36m<cell line: 150>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;31m## Receive all marketdata for cryptocurrency assets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0mtrading_pair_symbols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"BTCUSDT\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ETHUSDT\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"XRPUSDT\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m \u001b[0mdf_marketdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_marketdata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrading_pair_symbols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0;31m## Split the marketdata into different tables following star schema\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-15-97712bed2c7d>\u001b[0m in \u001b[0;36mget_marketdata\u001b[0;34m(trading_pair_symbols)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;31m# Execute DAG and combine collection of trading data dataframes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munionAll\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseries_tradingdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtransform_marketdata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_marketdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36munionAll\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m   3697\u001b[0m         \u001b[0mDataFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3698\u001b[0m         \"\"\"\n\u001b[0;32m-> 3699\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3700\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3701\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0munionByName\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"DataFrame\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallowMissingColumns\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"DataFrame\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'union'"]}]},{"cell_type":"code","source":["def setup_twitterAPI():       \n","    \"\"\"\n","    Description:  Calls the twitter api wrapper and provides credentials to it.         \n","    Parameters: \n","        None\n","    Returns: \n","        twitterAPI: The prepared API wrapper allowing to send request to twitter api\n","    \"\"\"\n","    # Provide all credentials to access the twitter API\n","    consumer_key = \"tuopEJa4I562s5QRtCfTiZnrI\"\n","    consumer_secret = \"tGD8leV9o7aGTE5dEXx77jm8TF5W8vYMLBKRZDbz6bcjqbDIz8\"\n","    access_token_key = \"1231985298751590404-iIWijICrpkjTijmE1wn9818axnEBl1\"\n","    access_token_secret = \"Bsj5d241AFWw8n8MTprWqVSnB7m1OTDOfwP3iYTDNHuZ8\"\n","\n","    # Get the API from the Twitter API wrapper and provide credentials\n","    twitterAPI = TwitterAPI(consumer_key, \n","                            consumer_secret, \n","                            access_token_key, \n","                            access_token_secret)\n","    \n","    print(\"Success: Twitter API was configured\")\n","    return twitterAPI\n","    \n","def get_parameters():       \n","    \"\"\"\n","    Description: Define all needed parameters to execute a twitter tweet search.\n","    Parameters: \n","        None\n","    Returns: \n","        parameters: Dictionary containing relevant search parameters\n","    \"\"\"\n","    \n","    # The string in the search term contains a special parameter lang: which requesting only english tweets.\n","    search_term = \"bitcoin lang:en\"\n","    \n","    # Defines the twitter product being used. The \"30 day\" product allows to access the last 30 days.\n","    product = \"Search Tweets\"\n","    \n","    # Name of the twitter application defined.\n","    label = \"simply_fire\"\n","    \n","    #  The twitter search begins at the startDate and stops at the endDate. However, the search may stop before\n","    #  in case the number of allowed request is reached (30/minute or 250/month).\n","    startDate = \"202205130000\" \n","    endDate = \"202205140000\"\n","    \n","    # The nextpage_token is necessary to enable pagination\n","    nextpage_token = None\n","\n","    parameters = {\"label\": label,\n","                  \"product\": product,\n","                  \"query\": search_term,\n","                  \"fromDate\": startDate, \n","                  \"toDate\": endDate,\n","                  \"next\": nextpage_token}\n","    \n","    print(\"Success: Parameters for Twitter Api were defined\")\n","    return parameters\n","\n","def get_twitterdata():       \n","    \"\"\"\n","    Description: Execute get request and save received tweets a dictionary containing only releveant data from tweet. \n","                 Note: The results and requests of the twitter api are strictly limited allowing 30 requests/minute and \n","                 250 requests/month. In addition only 100 are shown per request (page). Therefore, the request need to be splitted \n","                 (e.g. based on date) and executed several times applying next token.\n","                 Source:          \n","    Parameters: \n","        None\n","    Returns: \n","        cryptocurrency_tweets_pd: Dataframe containing all relevant cryptocurrency tweets for the desired time period\n","    \"\"\"\n","    \n","    # Make Twitter Api available and define parameters for twitter search\n","    twitterAPI = setup_twitterAPI()\n","    parameters = get_parameters()\n","    \n","    # As the request is a nested json object containing data which are not needed\n","    # the relevant details are extracted and persisted in a dictionary \n","    cryptocurrency_tweets_dict = {\"id\": [], \n","                                  \"date\": [], \n","                                  \"text\": [],\n","                                  \"user\": [], \n","                                  \"favorite_count\": [], \n","                                  \"retweet_count\": [], \n","                                  \"followers_count\": []}\n","\n","    # Execute actual twitter search based on search term considering pagination and english language\n","    # Filter out unnesseary tweet data and create dictionary containing relevant data\n","    while True:\n","        request = twitterAPI.request(\"tweets/search/%s/:%s\" % (parameters[\"product\"], parameters[\"label\"]),\n","                                                              {\"query\": parameters[\"query\"],\n","                                                               \"fromDate\": parameters[\"fromDate\"],\n","                                                               \"toDate\": parameters[\"toDate\"],\n","                                                               \"next\": parameters[\"next\"]})\n","        twitter_tweets = request.json()\n","        if (request.status_code != 200):\n","            print(\"Error: Twitter API Call was not successful\")\n","            request_status = False\n","            break\n","        for twitter_tweet in twitter_tweets[\"results\"]:\n","            cryptocurrency_tweets_dict[\"id\"].append(twitter_tweet[\"id\"])\n","            cryptocurrency_tweets_dict[\"date\"].append(twitter_tweet[\"created_at\"])\n","            cryptocurrency_tweets_dict[\"text\"].append(twitter_tweet[\"text\"])\n","            cryptocurrency_tweets_dict[\"user\"].append(twitter_tweet[\"user\"][\"screen_name\"])\n","            cryptocurrency_tweets_dict[\"favorite_count\"].append(twitter_tweet[\"favorite_count\"])\n","            cryptocurrency_tweets_dict[\"retweet_count\"].append(twitter_tweet[\"retweet_count\"])\n","            cryptocurrency_tweets_dict[\"followers_count\"].append(twitter_tweet[\"user\"][\"followers_count\"])\n","        if \"next\" not in twitter_tweets:\n","            print(\"Success: Twitter API Call executed\")\n","            request_status = True\n","            break\n","        parameters[\"next\"] = twitter_tweets[\"next\"]\n","    \n","    # To ease up post-processing use pandas to create dataframe containing all relevant cryptocurrency tweets\n","    cryptocurrency_tweets_pd = pd.DataFrame(cryptocurrency_tweets_dict)\n","    return cryptocurrency_tweets_pd, request_status\n","\n","def persist_twitterdata(df_twitterdata, request_status):\n","    \"\"\"\n","    Description: Persist the tweets in json format on the filesystem. This is necessary to decouple the from twitter api\n","                 due to result and call limitations. In case the Twitter Api limit is reached, no data will be persisted. \n","                 In that case refer to existing data in datasource/twitter_tweets folder.\n","    Parameters: \n","        df_twitterdata: Panda dataframe containing tweets for a specific period in the past\n","        request_status: In case the request was executed succesfully the status is set to True. Otherwise False. \n","    Returns: \n","        None\n","    \"\"\"    \n","    \n","    if request_status == True:\n","        cryptocurrency_tweets_df = spark.createDataFrame(df_twitterdata)\n","        cryptocurrency_tweets_df.write.json(path=\"data/twitter_tweets\", \n","                                            mode=\"append\")\n","        print(\"Success: Tweets were written into filesystem\")\n","    else:\n","        print(\"Error: Tweets were not written into filesystem\")\n","\n","## Access twitter (30 day premium) api and receive tweets\n","df_twitterdata, request_status = get_twitterdata()\n","\n","## Store twitter data on a local filesystem\n","persist_twitterdata(df_twitterdata, request_status)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":415},"id":"t8kE5FibKl9q","executionInfo":{"status":"error","timestamp":1684076331696,"user_tz":-330,"elapsed":988,"user":{"displayName":"2022 18059","userId":"02450271169094688564"}},"outputId":"259c9e1e-8d4b-4040-abc5-61bf31d934e7"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Success: Twitter API was configured\n","Success: Parameters for Twitter Api were defined\n"]},{"output_type":"error","ename":"Exception","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-12-0828d5811252>\u001b[0m in \u001b[0;36m<cell line: 139>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;31m## Access twitter (30 day premium) api and receive tweets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m \u001b[0mdf_twitterdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest_status\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_twitterdata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;31m## Store twitter data on a local filesystem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-12-0828d5811252>\u001b[0m in \u001b[0;36mget_twitterdata\u001b[0;34m()\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;31m# Filter out unnesseary tweet data and create dictionary containing relevant data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         request = twitterAPI.request(\"tweets/search/%s/:%s\" % (parameters[\"product\"], parameters[\"label\"]),\n\u001b[0m\u001b[1;32m     91\u001b[0m                                                               {\"query\": parameters[\"query\"],\n\u001b[1;32m     92\u001b[0m                                                                \u001b[0;34m\"fromDate\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"fromDate\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/TwitterAPI/TwitterAPI.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, resource, params, files, method_override, hydrate_type)\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0mresource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mendpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_endpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mendpoint\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mENDPOINTS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Endpoint \"%s\" unsupported'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mendpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m         \u001b[0;31m# check that the method is valid if the endpoint supports more than one method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubdomain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mENDPOINTS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mendpoint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mException\u001b[0m: Endpoint \"tweets/search/Search Tweets/:PARAM\" unsupported"]}]},{"cell_type":"code","source":["def extract_twitterdata():       \n","    \"\"\"\n","    Description: Load twitter data from external storage into a spark dataframe making it available for\n","                 denormalization\n","    Parameters: \n","        None\n","    Returns: \n","        cryptocurrency_tweets_df: Spark dataframe containing twitter tweets\n","    \"\"\"\n"," \n","    # Ensure proper data structure by providing custom schema. Make data structure more robust\n","    # by ensuring that a value for id is provided\n","    fields = [StructField(\"id\", LongType(), False),\n","              StructField(\"date\", StringType(), True),\n","              StructField(\"text\", StringType(), True),\n","              StructField(\"user\", StringType(), True), \n","              StructField(\"favorite_count\", LongType(), True),\n","              StructField(\"retweet_count\", LongType(), True),\n","              StructField(\"followers_count\", LongType(), True)]\n","                 \n","    final_schema = StructType(fields)  \n","    \n","    # Read twitter data provided as json following the schema definition\n","    cryptocurrency_tweets_df = spark.read.json(path=\"datasource/twitter_tweets\", schema=final_schema)\n","    print(\"Success: Twitter tweets were extracted\")\n","    return cryptocurrency_tweets_df\n","\n","## Process and denormalize tweets \n","def transform_twitterdata(tweets_df):       \n","    \"\"\"\n","    Description:              \n","    Parameters: \n","        transform_twitterdata: Contains all cryptocurrency tweets from filesystem\n","    Returns: \n","        None\n","    \"\"\"  \n","    \n","    # @udf: Convert ctime format to datetime and remove UTC timezone value as utc time is applicable for the entire project\n","    get_time_value_sequence_datetime = udf(lambda dateTimeUtc: datetime.datetime.strptime(dateTimeUtc, \"%a %b %d %H:%M:%S %z %Y\") \\\n","                                                                                .strftime(\"%Y-%m-%d %H:%M:%S\"))\n","    \n","    # Ensure data quality dropping null values and duplicates in id. \n","    tweets_df.na.drop(subset=[\"id\"]).dropDuplicates([\"id\"])\n","    \n","    # Convert ctime format to datetime allowing to extract date segments within dataframe\n","    tweets_df = tweets_df.withColumn(\"datetime\", get_time_value_sequence_datetime(tweets_df.date)) \n","    \n","    # Contains time related information for each tweet splitted into time segments.\n","    tweets_time_df = tweets_df.select([\"id\",\n","                                       month(\"datetime\").alias(\"month\"),\n","                                       year(\"datetime\").alias(\"year\"),\n","                                       dayofweek(\"datetime\").alias(\"weekday\"),\n","                                       weekofyear(\"datetime\").alias(\"weekofyear\"),\n","                                       \"datetime\"])\n","    \n","    # Contains username and how many followers belong to a user\n","    tweets_user_df = tweets_df.select(\"id\",\n","                                      \"user\",\n","                                      \"followers_count\")\n","    \n","    # Contains content related to an usertweet like the tweet message and how many times it was liked and retweeted.\n","    tweets_content_df = tweets_df.select(\"id\",\n","                                         \"text\",\n","                                         \"favorite_count\",\n","                                         \"retweet_count\")\n","    \n","    # Return dataframes as tuple for post-processing\n","    print(\"Success: Tweet dataframes were transformed\")\n","    return tweets_time_df, tweets_user_df, tweets_content_df\n","\n","## Extract tweets from filesystem\n","tweets_df = extract_twitterdata()  \n","## Process cryptocurrency tweets and denormalize tweets into time, user and content tweets\n","tweets_time_df, tweets_user_df, tweets_content_df = transform_twitterdata(tweets_df)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":380},"id":"hJVB4cWo9xsU","executionInfo":{"status":"error","timestamp":1684062813980,"user_tz":-330,"elapsed":3382,"user":{"displayName":"2022 18059","userId":"02450271169094688564"}},"outputId":"726bc7ff-b75d-4d5e-ece4-8815a92648d5"},"execution_count":null,"outputs":[{"output_type":"error","ename":"AnalysisException","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-15-3f36ff20ae40>\u001b[0m in \u001b[0;36m<cell line: 72>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;31m## Extract tweets from filesystem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m \u001b[0mtweets_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_twitterdata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;31m## Process cryptocurrency tweets and denormalize tweets into time, user and content tweets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0mtweets_time_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtweets_user_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtweets_content_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform_twitterdata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweets_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-15-3f36ff20ae40>\u001b[0m in \u001b[0;36mextract_twitterdata\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;31m# Read twitter data provided as json following the schema definition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mcryptocurrency_tweets_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"datasource/twitter_tweets\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfinal_schema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Success: Twitter tweets were extracted\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcryptocurrency_tweets_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/sql/readwriter.py\u001b[0m in \u001b[0;36mjson\u001b[0;34m(self, path, schema, primitivesAsString, prefersDecimal, allowComments, allowUnquotedFieldNames, allowSingleQuotes, allowNumericLeadingZero, allowBackslashEscapingAnyCharacter, mode, columnNameOfCorruptRecord, dateFormat, timestampFormat, multiLine, allowUnquotedControlChars, lineSep, samplingRatio, dropFieldIfAllNull, encoding, locale, pathGlobFilter, recursiveFileLookup, modifiedBefore, modifiedAfter, allowNonNumericNumbers)\u001b[0m\n\u001b[1;32m    416\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_spark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 418\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_spark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPythonUtils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoSeq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    419\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRDD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1323\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/errors/exceptions/captured.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    173\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAnalysisException\u001b[0m: [PATH_NOT_FOUND] Path does not exist: file:/content/datasource/twitter_tweets."]}]}]}